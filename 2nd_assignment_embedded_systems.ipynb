{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPrnj3ip8pC4DptB1i16YGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VictorBenoiston/using-keras-tuner/blob/main/2nd_assignment_embedded_systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Universidade Fderal Rural Do Semi-Árido\n",
        "## Mestrado em Engenharia da Computação - PPgCC\n",
        "## Sistemas embarcados\n",
        "### Docente: Silvio Fernandes\n",
        "### Discente: Victor Benoiston Jales de Oliveira\n",
        "### -> Segunda tarefa prática."
      ],
      "metadata": {
        "id": "ijSCs0mpy9Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the dependecies\n",
        "!pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylQiwWm_Ljdq",
        "outputId": "d56836d1-668f-46bf-df8f-97a762f2ef3d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FFmRU323yzRz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data()"
      ],
      "metadata": {
        "id": "AIKbImi2zvn-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyRprVxZzx8S",
        "outputId": "426ed7d6-ae55-49ef-ea15-f9c133d1d521"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpSDYZVzyU2",
        "outputId": "acaaad5d-c0a6-4913-9a2d-33a002073ef7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train = x_train.reshape(-1, 28, 28, 1)/ 255\n",
        "# x_test = x_test.reshape(-1, 28, 28, 1) / 255\n",
        "y_train = to_categorical(y_train[:10])\n",
        "y_test = to_categorical(y_test[:10])\n",
        "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tune tanh models\n",
        "# best_model_tanh = tune_tanh_models()\n",
        "\n",
        "# # Tune relu models\n",
        "# best_model_relu = tune_relu_models()"
      ],
      "metadata": {
        "id": "8iDGXFhTc3oH"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCpuXEJjz3rr",
        "outputId": "5e4ed9f8-c49c-424c-8d30-1a89b1473ab7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WFQlsQBz36z",
        "outputId": "57a1f028-e440-49dd-e145-93cc57c577d8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indice da imagem de digito de exemplo\n",
        "img = 5\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "print(x_train[img])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNNHYL0k0V47",
        "outputId": "2a21d239-480d-4b64-e571-aad518744be2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  25 100 122   7   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  33 151 208 252 252 252 146   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  40 152 244 252 253 224 211 252 232  40   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  15 152 239 252 252 252 216  31  37 252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  96 252 252 252 252 217  29   0  37 252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 181 252 252 220 167  30   0   0  77 252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  26 128  58  22   0   0   0   0 100 252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 252 252  60   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 110 121 122 121 202 252 194   3   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  10  53 179 253 253 255 253 253 228  35   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   5  54 227 252 243 228 170 242 252 252 231 117   6   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   6  78 252 252 125  59   0  18 208 252 252 252 252  87   7   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   5 135 252 252 180  16   0  21 203 253 247 129 173 252 252 184  66  49  49   0   0   0]\n",
            " [  0   0   0   0   0   3 136 252 241 106  17   0  53 200 252 216  65   0  14  72 163 241 252 252 223   0   0   0]\n",
            " [  0   0   0   0   0 105 252 242  88  18  73 170 244 252 126  29   0   0   0   0   0  89 180 180  37   0   0   0]\n",
            " [  0   0   0   0   0 231 252 245 205 216 252 252 252 124   3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 207 252 252 252 252 178 116  36   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  13  93 143 121  23   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"     Label of image {} is: {}\".format(img, y_train[img]))\n",
        "plt.imshow(x_train[img], cmap='gray');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cH_wB0Eb0au_",
        "outputId": "74606546-18ec-4c18-cdf3-82415ff1071d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label of image 5 is: [[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.max()"
      ],
      "metadata": {
        "id": "uysLca820ptB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69403569-78e5-4260-df79-9c6b39255e1e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5378702e-05"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.min()"
      ],
      "metadata": {
        "id": "xXOSmp6o0sGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6795e3-ff1d-4f18-c316-d0a087ea6849"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(training_images[i], cmap='binary') # cmap = 'gray'\n",
        "    plt.xlabel(training_labels[i])"
      ],
      "metadata": {
        "id": "75Yl06XS1OAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZrGVMsH0X3F"
      },
      "outputs": [],
      "source": [
        "training_images  = training_images / 255.0\n",
        "val_images = val_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khec4VhU8mkR"
      },
      "outputs": [],
      "source": [
        "print(training_images[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbxuCDhg-djD"
      },
      "outputs": [],
      "source": [
        "training_images.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8aRT6RL8fIG"
      },
      "outputs": [],
      "source": [
        "plt.imshow(training_images[2]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYMsyOk8-xnf"
      },
      "source": [
        "# Defining the models.\n",
        "\n",
        ">### Henceforth, we are going to work with different architectures, thus, the keras-tuner is a handy tool [(Check the documentation)](https://keras.io/keras_tuner/).\n",
        "\n",
        "> I defined 2 functions, each of them is going to test different architectures with 2 and 3 hidden layers, ne of them for the relu activation funciton, and other one for the tanh. I diveded them, because collab won't stop crashing during the training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "# Define a function for tuning models with tanh activation\n",
        "def tune_tanh_models(x_train, y_train, x_val, y_val):\n",
        "    def build_model(hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(keras.layers.Flatten())\n",
        "\n",
        "        num_hidden_layers = hp.Choice(\"num_hidden_layers\", [2, 3])\n",
        "\n",
        "        for i in range(num_hidden_layers):\n",
        "            model.add(\n",
        "                keras.layers.Dense(\n",
        "                    units=hp.Choice(f\"units_layer_{i}\", [10, 20, 30]),\n",
        "                    activation=\"tanh\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    tuner = RandomSearch(\n",
        "        build_model,\n",
        "        objective=\"accuracy\",\n",
        "        max_trials=10,\n",
        "        directory=\"tuner_directory\",\n",
        "        project_name=\"tanh_tuning_project\"\n",
        "    )\n",
        "\n",
        "    tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "    # Build the best model with the best hyperparameters\n",
        "    best_model = build_model(best_hyperparameters)\n",
        "\n",
        "    return best_hyperparameters, best_model\n",
        "\n",
        "# Define a function for tuning models with relu activation\n",
        "def tune_relu_models(x_train, y_train, x_val, y_val):\n",
        "    def build_model(hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(keras.layers.Flatten())\n",
        "\n",
        "        num_hidden_layers = hp.Choice(\"num_hidden_layers\", [2, 3])\n",
        "\n",
        "        for i in range(num_hidden_layers):\n",
        "            model.add(\n",
        "                keras.layers.Dense(\n",
        "                    units=hp.Choice(f\"units_layer_{i}\", [10, 20, 30]),\n",
        "                    activation=\"relu\",\n",
        "                )\n",
        "            )\n",
        "\n",
        "        model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "        learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    tuner = RandomSearch(\n",
        "        build_model,\n",
        "        objective=\"accuracy\",\n",
        "        max_trials=10,\n",
        "        directory=\"tuner_directory\",\n",
        "        project_name=\"relu_tuning_project\"\n",
        "    )\n",
        "\n",
        "    tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
        "\n",
        "    # Build the best model with the best hyperparameters\n",
        "    best_model = build_model(best_hyperparameters)\n",
        "\n",
        "    return best_hyperparameters, best_model"
      ],
      "metadata": {
        "id": "6QmO98Z2Y4kZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "best_hyperparameters_tanh, best_model_tanh = tune_tanh_models(x_train, y_train, x_val, y_val)\n",
        "best_hyperparameters_relu, best_model_relu = tune_relu_models(x_train, y_train, x_val, y_val)\n"
      ],
      "metadata": {
        "id": "aHi9NUXbZUHE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Access and print parameters for the best tanh model\n",
        "print(\"Parameters for the Best Tanh Model:\")\n",
        "for layer in best_model_tanh.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"Layer: {layer.name}\")\n",
        "        for param in weights:\n",
        "            print(f\"Parameter Shape: {param.shape}\")\n",
        "\n",
        "# Access and print parameters for the best relu model\n",
        "print(\"\\nParameters for the Best ReLU Model:\")\n",
        "for layer in best_model_relu.layers:\n",
        "    weights = layer.get_weights()\n",
        "    if weights:\n",
        "        print(f\"Layer: {layer.name}\")\n",
        "        for param in weights:\n",
        "            print(f\"Parameter Shape: {param.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv4bpuRUXa70",
        "outputId": "2fd09961-ce6b-4703-a2b4-52f461ed9f42"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters for the Best Tanh Model:\n",
            "\n",
            "Parameters for the Best ReLU Model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conclusion\n",
        "\n",
        "> The best model had an accuracy of 0.978."
      ],
      "metadata": {
        "id": "FhTP3qTWcMzi"
      }
    }
  ]
}